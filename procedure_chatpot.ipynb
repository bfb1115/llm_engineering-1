{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reimplemented Code (Compartmentalized)\n",
        "This notebook reimplements your original code with the same functionality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Optional) Installation Commands\n",
        "Uncomment if you're in a fresh environment (e.g., Google Colab) or missing dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install python-dotenv langchain_openai langchain_chroma plotly gradio langchain_community unstructured python-docx\n",
        "# !apt-get install -y libreoffice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and Environment Setup\n",
        "If you're using Google Colab with Google Drive, the drive mounting is included. If you are local or not using Drive, it will just print a warning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import gradio as gr\n",
        "import docx\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from langchain.document_loaders import (\n",
        "    DirectoryLoader,\n",
        "    TextLoader,\n",
        "    UnstructuredWordDocumentLoader\n",
        ")\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_chroma import Chroma\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# If running in Colab and using Google Drive:\n",
        "try:\n",
        "    from google.colab import drive, userdata\n",
        "except ImportError:\n",
        "    # If not in Colab, define placeholders\n",
        "    class MockDrive:\n",
        "        def mount(self, *args, **kwargs):\n",
        "            print(\"[WARNING] Google Drive mounting is unavailable outside Colab.\")\n",
        "    drive = MockDrive()\n",
        "\n",
        "    class MockUserdata:\n",
        "        def get(self, key, default=None):\n",
        "            return default\n",
        "    userdata = MockUserdata()\n",
        "\n",
        "# ------------------------------\n",
        "# Configure paths and environment\n",
        "# ------------------------------\n",
        "MODEL = \"gpt-4o\"\n",
        "db_name = \"/content/drive/MyDrive/Pedigo/procedures/vector_db2\"\n",
        "folders = [\"/content/drive/MyDrive/Pedigo/procedures\"]\n",
        "\n",
        "# Mount Google Drive (Colab)\n",
        "try:\n",
        "    drive.mount(\"/content/drive\")\n",
        "except:\n",
        "    pass  # Non-Colab environment\n",
        "\n",
        "load_dotenv()\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "persist_directory = db_name\n",
        "\n",
        "text_loader_kwargs = {\"encoding\": \"utf-8\"}\n",
        "chunk_size = 2000\n",
        "chunk_overlap = 400\n",
        "load_from_scratch = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Document Processing Function\n",
        "Loads `.doc`/`.docx` files, filters out temp files, and splits them into smaller chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_folders(\n",
        "    folders,\n",
        "    text_loader_kwargs,\n",
        "    chunk_size=2000,\n",
        "    chunk_overlap=400\n",
        "):\n",
        "    \"\"\"\n",
        "    Process documents in the specified folders and return chunks and documents.\n",
        "\n",
        "    Args:\n",
        "        folders (list): List of folder paths to process.\n",
        "        text_loader_kwargs (dict): Arguments for the text loader (e.g., encoding).\n",
        "        chunk_size (int): Size of text chunks for splitting.\n",
        "        chunk_overlap (int): Overlap between text chunks.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - documents (list): Loaded documents with metadata.\n",
        "            - chunks (list): Split document chunks.\n",
        "    \"\"\"\n",
        "    def filter_valid_files(folder, extensions):\n",
        "        \"\"\"Filter valid .doc and .docx files in a folder.\"\"\"\n",
        "        print(f\"Filtering files in folder: {folder} with extensions: {extensions}\")\n",
        "        all_files = []\n",
        "        for ext in extensions:\n",
        "            matching_files = glob.glob(os.path.join(folder, f\"**/*{ext}\"), recursive=True)\n",
        "            print(f\"Found {len(matching_files)} files with extension {ext}: {matching_files}\")\n",
        "            all_files.extend(matching_files)\n",
        "\n",
        "        # Exclude temporary files that start with \"~$\"\n",
        "        filtered_files = [\n",
        "            file for file in all_files if not os.path.basename(file).startswith(\"~$\")\n",
        "        ]\n",
        "        print(f\"Filtered files: {filtered_files}\")\n",
        "        return filtered_files\n",
        "\n",
        "    # Initialize an empty list for documents\n",
        "    documents = []\n",
        "\n",
        "    # Process each folder\n",
        "    for folder in folders:\n",
        "        print(f\"--- Processing folder: {folder} ---\")\n",
        "        doc_type = os.path.basename(folder)\n",
        "        print(f\"Determined document type: {doc_type}\")\n",
        "\n",
        "        # Filter and process .docx files\n",
        "        print(\"Filtering .docx files...\")\n",
        "        docx_files = filter_valid_files(folder, (\".docx\",))\n",
        "        print(f\"Found {len(docx_files)} valid .docx files: {docx_files}\")\n",
        "        try:\n",
        "            for file in docx_files:\n",
        "                print(f\"Processing .docx file: {file}\")\n",
        "                loader = UnstructuredWordDocumentLoader(file, **text_loader_kwargs)\n",
        "                docs = loader.load()  # Load returns a list of documents\n",
        "                print(f\"Loaded {len(docs)} documents from file: {file}\")\n",
        "                for doc in docs:\n",
        "                    doc.metadata[\"doc_type\"] = doc_type\n",
        "                    documents.append(doc)\n",
        "                    print(f\"Appended document with metadata: {doc.metadata}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing .docx file {file}: {e}\")\n",
        "\n",
        "        # Filter and process .doc files\n",
        "        print(\"Filtering .doc files...\")\n",
        "        doc_files = filter_valid_files(folder, (\".doc\",))\n",
        "        print(f\"Found {len(doc_files)} valid .doc files: {doc_files}\")\n",
        "        try:\n",
        "            for file in doc_files:\n",
        "                print(f\"Processing .doc file: {file}\")\n",
        "                loader = UnstructuredWordDocumentLoader(file, **text_loader_kwargs)\n",
        "                docs = loader.load()  # Load returns a list of documents\n",
        "                print(f\"Loaded {len(docs)} documents from file: {file}\")\n",
        "                for doc in docs:\n",
        "                    doc.metadata[\"doc_type\"] = doc_type\n",
        "                    documents.append(doc)\n",
        "                    print(f\"Appended document with metadata: {doc.metadata}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing .doc file {file}: {e}\")\n",
        "\n",
        "    print(f\"--- Completed processing folders ---\")\n",
        "    print(f\"Total documents loaded: {len(documents)}\")\n",
        "\n",
        "    # Check the loaded documents\n",
        "    print(\"Documents loaded:\")\n",
        "    for i, doc in enumerate(documents):\n",
        "        print(f\"Document {i + 1}: {doc}\")\n",
        "\n",
        "    # Split the documents into smaller chunks\n",
        "    print(\"Splitting documents into chunks...\")\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    chunks = text_splitter.split_documents(documents)\n",
        "    print(f\"Number of chunks created: {len(chunks)}\")\n",
        "\n",
        "    # List document types found\n",
        "    doc_types = set(chunk.metadata[\"doc_type\"] for chunk in chunks)\n",
        "    print(f\"Document types found: {', '.join(doc_types)}\")\n",
        "\n",
        "    return documents, chunks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Managing the Chroma Vector Store\n",
        "Handles loading an existing DB or creating a new one from scratch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def manage_vector_store(\n",
        "    folders,\n",
        "    embeddings,\n",
        "    persist_directory,\n",
        "    load_from_scratch=False,\n",
        "    text_loader_kwargs=None,\n",
        "    chunk_size=2000,\n",
        "    chunk_overlap=400\n",
        "):\n",
        "    \"\"\"\n",
        "    Manage a Chroma vector store: load from existing or process documents to create a new one.\n",
        "\n",
        "    Args:\n",
        "        folders (list): List of folder paths to process.\n",
        "        embeddings: Embedding function for Chroma.\n",
        "        persist_directory (str): Directory to persist or load the vector store.\n",
        "        load_from_scratch (bool): Whether to process documents from scratch.\n",
        "        text_loader_kwargs (dict): Arguments for text loading (e.g., encoding).\n",
        "        chunk_size (int): Size of text chunks for splitting.\n",
        "        chunk_overlap (int): Overlap between text chunks.\n",
        "\n",
        "    Returns:\n",
        "        Chroma: Loaded or created vector store.\n",
        "    \"\"\"\n",
        "    if not load_from_scratch and os.path.exists(persist_directory):\n",
        "        # Load existing vector store\n",
        "        print(\"[INFO] Loading existing vector store...\")\n",
        "        vectorstore = Chroma(\n",
        "            persist_directory=persist_directory,\n",
        "            embedding_function=embeddings\n",
        "        )\n",
        "        print(f\"Loaded vectorstore with {vectorstore._collection.count()} documents\")\n",
        "    else:\n",
        "        # Process documents and create a new vector store\n",
        "        print(\"[INFO] Loading documents and creating a new vector store...\")\n",
        "        documents, chunks = process_folders(\n",
        "            folders=folders,\n",
        "            text_loader_kwargs=text_loader_kwargs,\n",
        "            chunk_size=chunk_size,\n",
        "            chunk_overlap=chunk_overlap\n",
        "        )\n",
        "        print(\"[INFO] Creating and saving vector store...\")\n",
        "        vectorstore = Chroma.from_documents(\n",
        "            documents=chunks,\n",
        "            embedding=embeddings,\n",
        "            persist_directory=persist_directory\n",
        "        )\n",
        "        print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")\n",
        "\n",
        "    return vectorstore\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) The Chat Function\n",
        "Simple wrapper to invoke the conversation chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def chat(message, history):\n",
        "    \"\"\"\n",
        "    Simple wrapper to invoke the conversation chain.\n",
        "    Note: 'history' is not used here directly because the chain manages memory itself.\n",
        "    \"\"\"\n",
        "    result = conversation_chain.invoke({\"question\": message})\n",
        "    return result[\"answer\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Main Execution\n",
        "Putting it all together: embedding initialization, vector store management, TSNE visualizations, and launching the Gradio interface."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We define 'conversation_chain' globally so it's accessible in the chat() function.\n",
        "conversation_chain = None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Step 1: Initialize embeddings\n",
        "    print(\"[INFO] Initializing embeddings...\")\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    print(\"[INFO] Embeddings initialized successfully.\")\n",
        "\n",
        "    # Step 2: Manage vector store\n",
        "    vectorstore = manage_vector_store(\n",
        "        folders=folders,\n",
        "        embeddings=embeddings,\n",
        "        persist_directory=persist_directory,\n",
        "        load_from_scratch=load_from_scratch,\n",
        "        text_loader_kwargs=text_loader_kwargs,\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap\n",
        "    )\n",
        "\n",
        "    # Step 3: Fetch Collection and Extract Data\n",
        "    print(\"[INFO] Fetching vector store collection...\")\n",
        "    collection = vectorstore._collection\n",
        "    if collection.count() == 0:\n",
        "        print(\"[ERROR] Vector store is empty. Exiting...\")\n",
        "        exit()\n",
        "\n",
        "    result = collection.get(include=[\"embeddings\", \"documents\", \"metadatas\"])\n",
        "    vectors = np.array(result[\"embeddings\"])\n",
        "    documents = result[\"documents\"]\n",
        "    doc_types = [metadata[\"doc_type\"] for metadata in result[\"metadatas\"]]\n",
        "\n",
        "    # Step 4: Assign colors (simple approach; single category 'procedures')\n",
        "    categories = [\"procedures\"]\n",
        "    colors = [\n",
        "        [\"blue\"][categories.index(t)]\n",
        "        for t in doc_types\n",
        "    ]\n",
        "\n",
        "    # Step 5: 2D Visualization with t-SNE\n",
        "    print(\"[INFO] Reducing dimensionality to 2D for visualization...\")\n",
        "    n_samples = len(vectors)\n",
        "    perplexity = min(30, n_samples - 1)  # Perplexity must be < number of samples\n",
        "    tsne_2d = TSNE(n_components=2, random_state=42, perplexity=perplexity)\n",
        "    reduced_vectors_2d = tsne_2d.fit_transform(vectors)\n",
        "\n",
        "    print(\"[INFO] Creating 2D scatter plot...\")\n",
        "    fig_2d = go.Figure(data=[go.Scatter(\n",
        "        x=reduced_vectors_2d[:, 0],\n",
        "        y=reduced_vectors_2d[:, 1],\n",
        "        mode=\"markers\",\n",
        "        marker=dict(size=5, color=colors, opacity=0.8),\n",
        "        text=[\n",
        "            f\"Type: {t}<br>Text: {d[:100]}...\"\n",
        "            for t, d in zip(doc_types, documents)\n",
        "        ],\n",
        "        hoverinfo=\"text\"\n",
        "    )])\n",
        "\n",
        "    fig_2d.update_layout(\n",
        "        title=\"2D Chroma Vector Store Visualization\",\n",
        "        xaxis_title=\"t-SNE Dimension 1\",\n",
        "        yaxis_title=\"t-SNE Dimension 2\",\n",
        "        width=800,\n",
        "        height=600,\n",
        "        margin=dict(r=20, b=10, l=10, t=40)\n",
        "    )\n",
        "    fig_2d.show()\n",
        "\n",
        "    # Step 6: 3D Visualization with t-SNE\n",
        "    print(\"[INFO] Reducing dimensionality to 3D for visualization...\")\n",
        "    tsne_3d = TSNE(n_components=3, random_state=42, perplexity=perplexity)\n",
        "    reduced_vectors_3d = tsne_3d.fit_transform(vectors)\n",
        "\n",
        "    print(\"[INFO] Creating 3D scatter plot...\")\n",
        "    fig_3d = go.Figure(data=[go.Scatter3d(\n",
        "        x=reduced_vectors_3d[:, 0],\n",
        "        y=reduced_vectors_3d[:, 1],\n",
        "        z=reduced_vectors_3d[:, 2],\n",
        "        mode=\"markers\",\n",
        "        marker=dict(size=5, color=colors, opacity=0.8),\n",
        "        text=[\n",
        "            f\"Type: {t}<br>Text: {d[:100]}...\"\n",
        "            for t, d in zip(doc_types, documents)\n",
        "        ],\n",
        "        hoverinfo=\"text\"\n",
        "    )])\n",
        "\n",
        "    fig_3d.update_layout(\n",
        "        title=\"3D Chroma Vector Store Visualization\",\n",
        "        scene=dict(\n",
        "            xaxis_title=\"t-SNE Dimension 1\",\n",
        "            yaxis_title=\"t-SNE Dimension 2\",\n",
        "            zaxis_title=\"t-SNE Dimension 3\"\n",
        "        ),\n",
        "        width=900,\n",
        "        height=700,\n",
        "        margin=dict(r=20, b=10, l=10, t=40)\n",
        "    )\n",
        "    fig_3d.show()\n",
        "\n",
        "    # Step 7: Create a new Chat with OpenAI (GPT-4o-mini)\n",
        "    print(\"[INFO] Initializing ChatOpenAI with streaming enabled...\")\n",
        "    llm = ChatOpenAI(\n",
        "        temperature=0.7,          # Control randomness\n",
        "        model_name=\"gpt-4o-mini\", # Specify the model\n",
        "        streaming=True           # Enable streaming\n",
        "    )\n",
        "    print(\"[INFO] LLM initialized successfully.\")\n",
        "\n",
        "    # Step 8: Set up conversation memory\n",
        "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "    # Create a retriever from our vectorstore\n",
        "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 25})\n",
        "\n",
        "    # Build a ConversationalRetrievalChain from the LLM, retriever, and memory\n",
        "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
        "        llm=llm,\n",
        "        retriever=retriever,\n",
        "        memory=memory\n",
        "    )\n",
        "\n",
        "    # Step 9: Launch Gradio Chat Interface\n",
        "    print(\"[INFO] Launching Gradio chat interface...\")\n",
        "    view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "name": "ReimplementedNotebook"
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
